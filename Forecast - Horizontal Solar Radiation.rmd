---
title: "Forecasting - Horizontal Solar Radition reaching the ground"
output:
  html_notebook: default
  html_document: default
---
</br>

### Student Details

* Saurabh Mallik 

</br>

<h3> Introduction </h3>

<b>TASK 1: </b></br>
The objective of task 1 is to analyse and forecast the horizontal solar radation reaching the ground at a particular location. We need to provide best 2 years forecasts using the following:
a. DLM Models (DLM, POLYDLM, KOYCK etc.)
b. Dynlm Models (SES, Holt's etc.)
c. ETS Models (AAA, MAA etc.)

The purpose of task 1 research is to understand and analyse which model in each of the three categories best fits the series and projects the forecasts.

The data to undertake this task are
1. DATA1.CSV (2 variables ie Solar Radiation and Precipitation and 660 observations) and 
2. Data.X.CSV (predictor series with 1 variable and 24 observations).

<b>TASK 2: </b></br>
The objective of this task is to analyse the correlation between quarterly residential property price index (PPI) and quartely population change over previous quarter in Victoria between September 2003 and December 2016. The dataset provided to carry out this investigation is Data2.csv.

Tha main aim of task 2 is to identify whether the correlation between the two is spurious or not.

</br></br>

<h3> Methodology </h3>

To undertake this research, forecasting methods on R Studio are being used to infer from the dataset.

</br>

<h3> Research and Inferences </h3>
<h5> 1. Task 1</h5>

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(readr)
library(forecast)
library(TSA)
library(x12)
library(Hmisc)
library(AER)
library(tseries)
library(x13binary)
library(dLagM)
library(dynlm)
library(car)
library(xts)
```

Reading in the Data and preparing for analysis and converting to time series.
```{r}
data1 <- read_csv("~/Desktop/RMIT - Masters of Analytics/Year 1/Sem 2/MATH1307 - Forecasting/Forecasting - Ass 2/data1.csv")
datax <- read_csv("~/Desktop/RMIT - Masters of Analytics/Year 1/Sem 2/MATH1307 - Forecasting/Forecasting - Ass 2/data.x.csv")
datax.ts = ts(datax, start = c(2015,1), end = c(2016,12), frequency = 12)
solar = ts(data1$solar,start = c(1960,1), end = c(2014,12), frequency = 12)
ppt = ts(data1$ppt,start = c(1960,1), end = c(2014,12), frequency = 12)
data1.ts = ts(data1[,1:2])

```


Plotting the time series and checking for correlation.
```{r}
data.int = ts.intersect(solar , ppt)
colnames(data.int) =  c("Solar Radiation","Precipitation")
plot(data.int , yax.flip=T, main = "Fig1. Time series plot of solar radiation and Precipitation from 1960 to 2014")
```
From Fig. 1 it is not easy to discern any correlation, hence we must try to scale and fit plots in one graph.

Plotting a scaled timeseries to check for correlation
```{r}
data1.scaled = scale(data1.ts)
plot(data1.scaled, plot.type="s",col = c("blue", "red"), main = "Fig 2. Scaled Time series plot of solar radiation and Precipitation")
legend("topleft",lty=1, text.width = 28, col=c("Blue","red"), c("Solar", "Ppt"))
```
The two series appear to follow each other in an inverse manner. We expect to see some negative correlation between the two variables.

Checking for correlation between the two variables.
```{r}
cor(data1.ts)
```
Since there is negative correlation, we can infer that the series are inversely related to each other.

We also conduct an ACF and PACF test to test for trend and seasonality.
```{r}
par(mfrow = c(1,2))
acf(solar, "ACF for Solar Radiation")
pacf(solar, "PACF for Solar Radiation")
```
From the ACF we can see the slowly decomposing lags showing existence of trend and seasonality because of the presence of curves. The high 1st lag in PACF also shows evidence of trend.

In order to get the best fit forecasts, we need to model using DLM, Dynlm and ETS each, to find the best suitable fits.

1. DLM Fitting

We first attempt using dlm fitting.
```{r}
model1p = dlm(x = as.vector(ppt) , y = as.vector(solar) , q = 12 , show.summary = TRUE)
vif(model1p$model)
```
We see that as we increase lags from 1 through 12, at q = 2 the R squared value is coming to .3077 and hence its not a very good fit. We also find that the lags are not affected by multicollinearity, as values of VIF test are below 10.

We continue to check residuals.
```{r}
checkresiduals(model1p$model$residuals)
```
The residuals seem to be slightly random, but there are many extreme lags in the ACF test, suggesting evidence of serial correlation.

```{r}
bgtest(model1p$model)
```
The Breusch-Godfrey test having a significant p value (< 2.2e-16) shows that the model is significant and fits the data well, although some coefficients are insignificant.

We next try the polydlm fitting.
```{r}
model2p = polyDlm(x = as.vector(ppt) , y = as.vector(solar) , q = 12 , k = 2, show.beta = TRUE , show.summary = TRUE)
vif(model2p$model)
```
Model and all parameters are significant, but R squared value of fit is low ie. .3087.

```{r}
checkresiduals(model2p$model$residuals)
```
The residuals randomness is still not good, and there are still many extreme lags in the ACF test suggesting serial correlation.

```{r}
bgtest(model2p$model)
```
The test has a significant p value shows that the model is significant and fits the data well, despite the low R squared value.

We next use the Koyck fitting.
```{r}
model3p = koyckDlm(x = as.vector(ppt) , y = as.vector(solar) , show.summary = TRUE)
vif(model3p$model)
```
We see that the Koyck model shows a higher R squared value of .7591 and all lags and model are significant, hence it is a better fit than the previous models. We run diagnostic check.


```{r}
checkresiduals(model3p$model$residuals)
```
The randomness is much better, but there are still some extreme values in the ACF plot showing serial correlation.

```{r}
bgtest(model3p$model)
```
The model is statistically significant, since it has a very low p value.

We move on to the ardlm fitting.
```{r}
model4p = ardlDlm(x = as.vector(ppt) , y = as.vector(solar) , p = 2 , q = 2 , show.summary = TRUE)
```
The R squared value for the ardlm is coming to .9186 which shows a very good fit for the model. Intercept is significant and a lot of significant y,t lags. We move on to diagnostic testing.

```{r}
checkresiduals(model4p$model$residuals)
```
We see that the randsomness is much better than the previous models and even less extreme lags showing low correlation and symmetric histogram.

```{r}
bgtest(model4p$model)
```
With a p value < 2.2e-16 the model is statistically significant and the best DLM model fit so far. 


2. DYNLM Fitting

For dynlm fitting we first start off with SES fitting.
```{r}
fit1.ses = ses(solar, initial="simple", h=24) 
summary(fit1.ses)
```
With a simple ses fitting we see that the MASE value is .636 which is still high. We do diagnostic check.

```{r}
checkresiduals(fit1.ses)
```
The randomness in the series is low, and extreme lags show existence of serial correlation.


We next try the holt model.
```{r}
fit2.holt = holt(solar, initial="simple", h=24)
summary(fit2.holt)
```
The Holt model gives us a MASE value of .461036, which is lower than the SES model. We move on to diagnostic check.

```{r}
checkresiduals(fit2.holt)
```
The randomness in the data is much better, however there is still existence of serial correlation.

```{r}
fit3.hw = hw(solar,seasonal="additive", h=2*frequency(solar))
summary(fit3.hw) 
```
The Holt-Winter's additive method gives us a MASE value of .2541887, which is the lowest we have seen amongst the dynlm models, hence we move on to diagnostic check

```{r}
checkresiduals(fit3.hw)
```


The randomness for the series is very good. Histogram is symmetric. Few extreme lags but much better than previous models, also the model is significant and has the lowest MASE calue of .254, hence we will use this for the forecast.


```{r}

plot(solar, type="o", xlim = c(1959, 2019),  ylab = "Solar Radiation", xlab = "Year", 
     main="Fig 4. Solar Radiation Forecasts 2 years DLM and Dynlm")                       
lines(ts(model4p.forecasts[1:24],start = 2015),col="Purple",type="o")
lines(fit3.hw$mean, type="o", col="cyan")
lines(fitted(fit3.hw), col="cyan")
legend("topleft",lty=1, pch = 1, text.width = 20, col=c("black","purple","cyan"), 
       c("Solar Radiation series","ARDL","Holt-Winter's Additive"))
```

3. ETS Model fitting.

We beging ETS model fitting by using an ANN model.
```{r}
fit1.etsA = ets(solar, model="ANN")
summary(fit1.etsA)

```
From the model we see that the MASE is very high at .6368, we continur to diagnostic check.


```{r}
checkresiduals(fit1.etsA)
```

Even though the Ljung-Bos test is significant, there is low randomness in the residuals and extreme lags which show signs of correlation.

We next try MNN model.
```{r}
fit2.etsM = ets(solar, model="MNN")
summary(fit2.etsM)
```
The MASE for the MNN model is also high at .66787 and it has increased from additive type.


```{r}
checkresiduals(fit2.etsM)
```
The series doesnt show randomness and the ACF extreme lags show serial correlation. Even though the Ljung-Box test is significant, this model is not very good.

We next try using AAN model
```{r}
fit3.etsA = ets(solar, model="AAN")
summary(fit3.etsA)
```
The MASE for the AAN model is now .4308, which is lower than the previous two models. We move to diagnostic testing.

```{r}
checkresiduals(fit3.etsA)
```
The ACF plots still shows signs of seasonality, and the randomness is not very evident in the series. Hence, we move on to the next model.

We use the MAA model.
```{r}
fit4.etsA = ets(solar, model="MAA")
summary(fit4.etsA)
```
We see that the MASE for the MAA models has decreased from the previous models to .376, and we move on to diagnostic checking.


```{r}
checkresiduals(fit4.etsA)
```
The variance and randomness of the series looks good, signs of seasonality in the ACF is gone, and Histogram looks symmetric. The MAA model seems to be catching the serial correlation structure in the series. Hence we will go ahead and forecast using this.

```{r}

frc.MAA = forecast(fit4.etsA , h = 2* frequency(solar))
plot(solar, type="o", xlim = c(1959, 2019),  ylab = "Solar Radiation", xlab = "Year", 
     main="Fig 5. Solar Radiation Forecasts 2 years DLM,Dynlm and ETS")                       
lines(ts(model4p.forecasts[1:24],start = 2015),col="Purple",type="o")
lines(fit3.hw$mean, type="o", col="cyan")
lines(fitted(fit4.etsA), col="green", lty=1)
lines(fitted(fit3.hw), col="cyan")
lines(frc.MAA$mean,col="green", type="o")
legend("topleft",lty=1, pch = 1, text.width = 20, col=c("black","purple","cyan","green"), 
       c("Solar Radiation series","ARDL","Holt-Winter's Additive", "ets(MAA)"))
```

In Fig 5. we can see the forecasts for DLM, DYNlm and ets Models that were chosen to be the best fit. Discussion on findings for task 1, is noted below in the conslusions section.

</br></br></br>

<h5> 2. Task 2</h5> </br></br>

Reading in the data and preparing for analysis
```{r}
data2 <- read_csv("~/Desktop/RMIT - Masters of Analytics/Year 1/Sem 2/MATH1307 - Forecasting/Forecasting - Ass 2/data2.csv")
PPI = ts(data2$price, start = c(2003,3), frequency = 4)
change = ts(data2$change, start = c(2003,3), frequency = 4)
data2 = ts(data2[,2:3], start = c(2003,3), frequency = 4)
```

Plotting the two series.
```{r}
data2.joint=ts.intersect(PPI,change)
colnames(data2.joint) =  c("PPI","Population Change")
plot(data2.joint , yax.flip=T, main = "Fig6. Timeseries plot of PPI and Population Change from Q3 2003 - Q4 2016")
```
From Fig6. we can see in the two series, it seems that there might be a correlation between them, as PPI increases so does population change, as according to the visual trend in the two plots.

We will know display the CCF function to take another look at the correlation structure between the two series.
```{r}
ccf(as.vector(data2.joint[,1]), as.vector(data2.joint[,2]),ylab='CCF', main = "Fig7. Sample CCF between PPI and Population Change")
```
There appears to be a high correlation structure in the CCF plot, and a lot of cross -correlations are significantly different from zero.

We will now take the CCF of the differenced series to see if it has any variation to the previous CCF Plot.

```{r}
ccf(as.vector(diff(data2.joint[,1])), as.vector(diff(data2.joint[,2])),ylab='CCF', main = "Fig8. Sample CCF between Differenced PPI and Population Change")
```
There appear to be some significant correlation in the CCF between the differenced time-series. The number of significant lags have reduced significantly.

This is not enough to say for certain, that there is no spurious correlation between the two series.

We will move on to prewhitening the series.

```{r}
data2.dif=ts.intersect(diff(diff(PPI, lag = 4)),diff(diff(change, lag = 4)))
```

```{r}
prewhiten(as.vector(data2.dif[,1]), as.vector(data2.dif[,2]), ylab='CCF', main="Fig9. Sample CFF after prewhitening")
```
From Fig9. it seems that there is no correlation between residential property price index (PPI) and quarterly poupulation change.

The significant correlations in Fig 7 and 8 can be said to be related to false alarm rate of CCF.

Therefore, it seems that the two series are uncorrelated, and the strong correlation pattern found between them in the dataset is indeed spurious.


</br></br></br>


<h3> Conclusion </h3>

<b> Task 1: </b></br>
From task 1, we found 1 model in each category ie DLM, DYNLM and ETS, to forecast 2 year ahead horizontal monthly solar radiation. The forecast plots in Fig5 below show the same.

```{r}

frc.MAA = forecast(fit4.etsA , h = 2* frequency(solar))
plot(solar, type="o", xlim = c(1959, 2019),  ylab = "Solar Radiation", xlab = "Year", 
     main="Fig 5. Solar Radiation Forecasts 2 years DLM,Dynlm and ETS")                       
lines(ts(model4p.forecasts[1:24],start = 2015),col="Purple",type="o")
lines(fit3.hw$mean, type="o", col="cyan")
lines(fitted(fit4.etsA), col="green", lty=1)
lines(fitted(fit3.hw), col="cyan")
lines(frc.MAA$mean,col="green", type="o")
legend("topleft",lty=1, pch = 1, text.width = 20, col=c("black","purple","cyan","green"), 
       c("Solar Radiation series","ARDL","Holt-Winter's Additive", "ets(MAA)"))
```

</br></br>
<b> Task 2: </b></br>
The two time series residential property price index (PPI) and quarterly population change (change) are in fact uncorrelated as we saw in the research and inference stage, and from CCF and prewhitening inferences we can say that the two series are indeed spuriously correlated.
</br></br></br></br>